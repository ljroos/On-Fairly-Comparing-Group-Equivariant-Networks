import matplotlib.pyplot as plt
import numpy as np
import pytorch_lightning as pl
import torch
from sklearn.datasets import make_moons
from torch.utils.data import DataLoader

from models.layers.equivariant.group_definitions import D4_subgroups

# amount of noise used throughout all experiments
NOISE_LEVEL = 0.125

# For moons with NOISE_LEVEL noise.
# trivial
TRIVIAL_MOONS_MEAN = np.array([[0.5, 1.25]])
TRIVIAL_MOONS_STD = np.array([[0.8751, 0.5097]])

# fliph and or flipw
FLIPH_AND_OR_FLIPW_MOONS_MEAN = np.array([[0.0, 0.0]])
FLIPH_AND_OR_FLIPW_MOONS_STD = np.array([[1.0049, 1.3479]])

MOONS_MEAN_STD = {
    "trivial": (TRIVIAL_MOONS_MEAN, TRIVIAL_MOONS_STD),
    "flipH_and_or_flipW": (FLIPH_AND_OR_FLIPW_MOONS_MEAN, FLIPH_AND_OR_FLIPW_MOONS_STD),
}


# above generated by
def _calc_moons_mean_std(augment):
    x, _ = _make_invariant_moons(int(1e7), augment=augment, seed=0)
    return np.mean(x, axis=0), np.std(x, axis=0)


def _augment_data(x, group: str, y=None):
    # flip ops
    flipW = np.array([-1.0, 1.0])
    flipH = np.array([1.0, -1.0])
    flipWY = np.array([-1.0, -1.0])

    # rotation matrices
    rot90 = np.array([[0.0, 1.0], [-1.0, 0.0]])
    rot180 = np.array([[-1.0, 0.0], [0.0, -1.0]])
    rot270 = np.array([[0.0, -1.0], [1.0, 0.0]])

    X = [x]
    if group == "trivial":
        pass
    elif group == "flipW":
        X.append(x * flipW)
    elif group == "flipH":
        X.append(x * flipH)
    elif group == "flipH_and_or_flipW":
        X.append(x * flipW)
        X.append(x * flipH)
        X.append(x * flipWY)
    elif group == "rot180":
        X.append(torch.matmul(x, rot180))
    elif group == "rot90":
        X.append(np.matmul(x, rot90))
        X.append(np.matmul(x, rot180))
        X.append(np.matmul(x, rot270))
    else:
        raise NotImplementedError(f"group {group} not implemented.")
    x = np.concatenate(X, axis=0)
    if y is not None:
        group_order = len(D4_subgroups[group]["members"])
        y = np.concatenate([y] * group_order)
        return x, y
    return x


def _make_invariant_moons(num_canonical_samples, augment, seed):
    x, y = make_moons(
        n_samples=num_canonical_samples, noise=NOISE_LEVEL, random_state=seed
    )
    x[:, 1] += 1

    # augment data
    x, y = _augment_data(x, group=augment, y=y)

    # randomly permute
    rng = np.random.default_rng(seed)
    perm = rng.permutation(x.shape[0])
    x = x[perm]
    y = y[perm]

    return x, y


def _standardize_invariant_moons(x):
    # standardize
    mean, std = MOONS_MEAN_STD["flipH_and_or_flipW"]
    x = (x - mean) / std
    return x


class MoonsDataModule(pl.LightningDataModule):
    def __init__(
        self,
        num_canonical_samples: int = 1000,
        batch_size: int = 256,
        seed: int = 42,
        augment: str = "trivial",
    ):
        super().__init__()
        self.batch_size = batch_size
        self.seed = seed
        self.num_canonical_samples = num_canonical_samples

        x, y = _make_invariant_moons(num_canonical_samples, augment, seed)
        x = _standardize_invariant_moons(x)

        x = torch.from_numpy(x).float()
        y = torch.from_numpy(y).long()
        self.num_samples = x.shape[0]

        self.full = torch.utils.data.TensorDataset(x, y)

        num_train = int(0.7 * self.num_samples)
        num_val = int(0.1 * self.num_samples)
        num_test = self.num_samples - num_train - num_val
        self.train, self.val, self.test = torch.utils.data.random_split(
            self.full,
            [
                num_train,
                num_val,
                num_test,
            ],
        )

    def prepare_data(self):
        pass

    def setup(self, stage: str):
        pass

    def train_dataloader(self):
        return DataLoader(
            self.train,
            batch_size=self.batch_size,
            shuffle=True,
            drop_last=True,
        )

    def val_dataloader(self):
        return DataLoader(self.val, batch_size=self.batch_size)

    def test_dataloader(self):
        return DataLoader(self.test, batch_size=self.batch_size)

    def predict_dataloader(self):
        return DataLoader(self.test, batch_size=self.batch_size)


def make_pinwheel(num_samples: int, random_state: int = 42):
    rng = np.random.RandomState(random_state)
    radial_std = 0.3
    tangential_std = 0.2
    num_classes = 1
    rate = 1.5
    rads = np.linspace(0, 2 * np.pi, num_classes, endpoint=False)

    features = rng.randn(num_samples, 2) * np.array([radial_std, tangential_std])
    features[:, 0] += 1.0
    labels = rng.randint(0, num_classes, num_samples)

    angles = rads[labels] + rate * np.exp(features[:, 0])
    rotations = np.stack(
        [np.cos(angles), -np.sin(angles), np.sin(angles), np.cos(angles)]
    )
    rotations = np.reshape(rotations.T, (-1, 2, 2))

    wheels = np.einsum("ti,tij->tj", features, rotations)

    return wheels, labels


def rot_matrix(theta):
    return np.array([[np.cos(theta), -np.sin(theta)], [np.sin(theta), np.cos(theta)]])


class PinwheelDataModule(pl.LightningDataModule):
    def __init__(
        self,
        num_samples_per_pin: int = 1000,
        batch_size: int = 256,
        seed: int = 42,
        augment: str = "trivial",
    ):
        super().__init__()
        if augment != "trivial":
            raise NotImplementedError(
                f"group {augment} not allowed for pinwheel augment. Only trivial. Parameter is ignored."
            )
        self.batch_size = batch_size
        self.seed = seed
        self.num_samples = 4 * num_samples_per_pin

        x, y = make_pinwheel(3 * num_samples_per_pin, random_state=seed)
        x = _augment_data(x, group="rot90")
        y = np.concatenate([y, y + 1, y + 2, y + 3], axis=0)

        # standardize
        x = x / np.array([0.759, 0.759])  # 0.759 -> std when num_samples is large

        x = torch.tensor(x, dtype=torch.float32)
        y = torch.tensor(y, dtype=torch.long)

        self.full = torch.utils.data.TensorDataset(x, y)

        self.train, self.val, self.test = torch.utils.data.random_split(
            self.full, [self.num_samples, self.num_samples, self.num_samples]
        )

    def prepare_data(self):
        pass

    def setup(self, stage: str):
        pass

    def train_dataloader(self):
        return DataLoader(
            self.train,
            batch_size=self.batch_size,
            shuffle=True,
            drop_last=True,
        )

    def val_dataloader(self):
        return DataLoader(
            self.val,
            batch_size=self.batch_size,
        )

    def test_dataloader(self):
        return DataLoader(self.test, batch_size=self.batch_size)

    def predict_dataloader(self):
        return DataLoader(self.test, batch_size=self.batch_size)


def plot_batch(
    x,
    y=None,
    save_fig=False,
    fig_name=None,
    ax=None,
    show_plot=True,
    remove_lines=False,
    alpha=0.75,
):
    if type(x) == torch.tensor:
        x = x.detach().cpu()
        if y is not None:
            y = y.detach().cpu()
    # plot an empty axis with the origin and axes at the center, from -10 to 10 on both axes
    if ax is None:
        fig, ax = plt.subplots(figsize=(10, 10))
    ax.set_xlim(-2.5, 2.5)
    ax.set_ylim(-2.5, 2.5)
    ax.set_aspect("equal")
    if remove_lines:
        ax.axhline(y=0, color="gray", alpha=alpha, linestyle="--")
        ax.axvline(x=0, color="gray", alpha=alpha, linestyle="--")

        # remove x and y ticks
        ax.set_xticks([])
        ax.set_yticks([])
    else:
        ax.axhline(y=0, color="k", alpha=0.5)
        ax.axvline(x=0, color="k", alpha=0.5)
        ax.grid(True)

    # plot points
    ax.scatter(x[:, 0], x[:, 1], c=y, cmap="Spectral", alpha=alpha, s=10)
    plt.tight_layout()
    if save_fig:
        assert fig_name is not None, "must provide fig_name"
        plt.savefig(fig_name, dpi=300)
        plt.close()
    else:
        if show_plot:
            plt.show()


if __name__ == "__main__":
    datamod = PinwheelDataModule(
        num_samples_per_pin=5000, batch_size=5000, seed=42, augment="rot90"
    )
    train_loader = datamod.train_dataloader()
    pin, labels = next(iter(train_loader))
    plot_batch(pin, labels, save_fig=False)

    datamod = MoonsDataModule(
        num_canonical_samples=5000,
        batch_size=5000,
        seed=42,
        augment="flipH_and_or_flipW",
    )
    train_loader = datamod.train_dataloader()
    pin, labels = next(iter(train_loader))

    plot_batch(pin, labels, save_fig=False)

    # pin, labels = make_pinwheel(5000)
    # pin = pin - pin.mean(axis=0)
    # pin = pin / pin.std(axis=0)
    # rotate the pinwheel by 45 degrees
    # pin2 = pin @ rot_matrix(np.pi / 2)
    # pin3 = pin2 @ rot_matrix(np.pi / 2)
    # pin4 = pin3 @ rot_matrix(np.pi / 2)
    # pin = np.concatenate([pin, pin2, pin3, pin4], axis=0)
    # print(pin.mean(axis=0))
    # print(pin.std(axis=0))
    # labels2 = labels
    # labels = np.concatenate([labels, labels + 1, labels + 2, labels + 3], axis=0)
    # print(labels)
    # fig, ax = plt.subplots(1, 2, figsize=(9, 3), sharex=True, sharey=True)
    # x_0 = pin[:, 0]
    # x_1 = pin[:, 1]
    # # solid dot marker
    # ax[0].scatter(x_0, x_1, alpha=0.4, c=labels, marker=".", s=15)
    # # ax[1].scatter(pin2[:, 0], pin2[:, 1], alpha=0.4, c=labels2, marker=".", s=15)
    # # plot axis lines
    # ax[0].axhline(y=0, color="k", alpha=0.5)
    # ax[0].axvline(x=0, color="k", alpha=0.5)
    # plt.show()
    exit()

    # This KDE plot function call constructs an estimate of the density from the sample
    import seaborn as sns

    sns.kdeplot(x=x_0, y=x_1, cmap="Blues", shade=True, bw_adjust=0.5, ax=ax[1])

    ax[0].set_title("Pinwheel scatterplot")
    ax[1].set_title("Pinwheel density estimate")

    for axi in ax:
        axi.set_xlim((-4, 4))
        axi.set_ylim((-4, 4))
        axi.axes.xaxis.set_visible(False)
        axi.axes.yaxis.set_visible(False)
    plt.subplots_adjust(wspace=0.05, hspace=0.05)
    plt.show()
