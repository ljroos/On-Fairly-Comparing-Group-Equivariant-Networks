{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "# magic commands, make python reimport modules when code is changed\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "\n",
    "import sys\n",
    "\n",
    "sys.path.append(\".utilities/\")\n",
    "\n",
    "from utilities.download import download_sweep\n",
    "from utilities.process import create_error_plots_custom\n",
    "\n",
    "# set pandas dataframe display options\n",
    "pd.set_option(\"display.max_columns\", 500)\n",
    "pd.set_option(\"display.width\", 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "USE_BIG_DATA = True\n",
    "USE_FULL_AUGMENT = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# make figure folder\n",
    "if not os.path.exists(\"figures\"):\n",
    "    os.makedirs(\"figures\")\n",
    "\n",
    "SAVE_FOLDER = \"csv-files\"\n",
    "SWEEPS = {\n",
    "    \"moons\": [\"204gpz3v\"],\n",
    "    \"mnist\": [\"rut3a738\"],\n",
    "    \"downsampled_mnist\": [\"npnuge21\"],\n",
    "    \"cifar10\": [\"2uxccm2r\", \"669xhx85\", \"sgffog8z\"],\n",
    "}\n",
    "\n",
    "full_dfs = {}\n",
    "for dataset, sweep_list in SWEEPS.items():\n",
    "    print(f\"Downloading {dataset}\")\n",
    "    sweep_save_folder = os.path.join(SAVE_FOLDER, dataset)\n",
    "    if not os.path.exists(sweep_save_folder):\n",
    "        os.makedirs(sweep_save_folder)\n",
    "\n",
    "    dataset_dfs = []\n",
    "    for sweep in sweep_list:\n",
    "        sweep_id = f\"ljroos-msc/knot-solver/{sweep}\"\n",
    "        save_loc = os.path.join(sweep_save_folder, f\"{dataset}_{sweep}.csv\")\n",
    "        _ = download_sweep(sweep_id, save_loc, override_existing=False)\n",
    "\n",
    "        dataset_dfs.append(pd.read_csv(save_loc))\n",
    "\n",
    "    print()\n",
    "\n",
    "    full_dfs[dataset] = pd.concat(dataset_dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "group_info = {\n",
    "    \"trivial\": [1, \"Trivial\", True],\n",
    "    # D4\n",
    "    \"flipH\": [2, \"FlipH\", (True,)],\n",
    "    \"flipW\": [2, \"FlipW\", (True)],\n",
    "    \"rot180\": [2, \"Rot180\", False],\n",
    "    \"transpose\": [2, \"Transpose\", False],\n",
    "    \"antidiagonal_transpose\": [2, \"Anti-Transpose\", False],\n",
    "    \"flipH_and_or_flipW\": [4, \"FlipH and/or W\", False],\n",
    "    \"rot180_and_or_transpose\": [4, \"Main- and/or Anti-Transpose\", False],\n",
    "    \"rot90\": [4, \"Rot90\", True],\n",
    "    \"D4\": [8, \"FlipRot90\", True],\n",
    "    # Z_2^7\n",
    "    \"translateH\": [7, \"TranslateH\"],\n",
    "    \"translateW\": [7, \"TranslateW\"],\n",
    "    \"translateH_and_W\": [7, \"TranslateDiag\"],\n",
    "    \"translateH_and_or_W\": [49, \"TranslateH and/or W\"],\n",
    "}\n",
    "\n",
    "group_sizes = {key: value[0] for key, value in group_info.items()}\n",
    "proper_names = {key: value[1] for key, value in group_info.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for dataset, df in full_dfs.items():\n",
    "    full_dfs[dataset][\"group_order\"] = full_dfs[dataset][\"group\"].map(\n",
    "        lambda x: group_sizes[x]\n",
    "    )\n",
    "    full_dfs[dataset][\"group_proper_name\"] = full_dfs[dataset][\"group\"].map(\n",
    "        lambda x: proper_names[x]\n",
    "    )\n",
    "    full_dfs[dataset][\"parameter_factor\"] = full_dfs[dataset][\n",
    "        \"hidden_group_channels\"\n",
    "    ] / full_dfs[dataset][\"group\"].map(lambda x: np.sqrt(group_sizes[x]))\n",
    "    full_dfs[dataset][\"sqrt_total_smoothness\"] = np.sqrt(\n",
    "        full_dfs[dataset][\"total_smoothness\"]\n",
    "    )\n",
    "    full_dfs[dataset][\"expected_gradient_norm_normalized_smoothness\"] = (\n",
    "        full_dfs[dataset][\"sqrt_total_smoothness\"]\n",
    "        / full_dfs[dataset][\"expected_gradient_norm\"]\n",
    "    )\n",
    "    full_dfs[dataset][\"generalization_gap\"] = (\n",
    "        full_dfs[dataset][\"test_loss\"] - full_dfs[dataset][\"val_loss\"]\n",
    "    )\n",
    "    full_dfs[dataset][\"generalization_ratio\"] = (\n",
    "        full_dfs[dataset][\"test_loss\"] - full_dfs[dataset][\"val_loss\"]\n",
    "    ) / full_dfs[dataset][\"val_loss\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "# downloaded data from https://wandb.ai/ljroos-msc/mosaic/sweeps/w705aehx/table?workspace=user-luro\n",
    "# not sure if link will work for others.\n",
    "\n",
    "# all target columns of interest\n",
    "target_cols = [\n",
    "    \"total_num_knots\",\n",
    "    \"expected_knot_uniformity\",\n",
    "    \"expected_knot_entropy\",\n",
    "    \"expected_gradient_norm\",\n",
    "    \"sqrt_total_smoothness\",\n",
    "    \"val_loss\",\n",
    "    \"test_loss\",\n",
    "]\n",
    "\n",
    "# main big table\n",
    "main_target_cols = [\n",
    "    \"total_num_knots\",\n",
    "    \"expected_knot_uniformity\",\n",
    "    \"expected_gradient_norm\",\n",
    "    \"sqrt_total_smoothness\",\n",
    "    \"val_loss\",\n",
    "]\n",
    "\n",
    "# for 'appendix'\n",
    "alternative_target_cols = [\n",
    "    \"expected_knot_entropy\",\n",
    "    \"expected_gradient_norm_normalized_smoothness\",\n",
    "    \"val_loss\",\n",
    "    \"test_loss\",\n",
    "    \"generalization_gap\",\n",
    "]\n",
    "\n",
    "# for important shot mnist\n",
    "minimal_key_target_cols = [\"total_num_knots\", \"sqrt_total_smoothness\", \"val_loss\"]\n",
    "\n",
    "target_cols = [\"val_loss\", \"test_loss\"]\n",
    "\n",
    "pairs = [(0, 2), (2, 3), (3, 5), (5, 8), (8, 1), (1, 7), (7, 9), (9, 4), (4, 6), (6, 0)]\n",
    "\n",
    "\n",
    "def get_alternative_target_cols(pair):\n",
    "    return [\n",
    "        f\"num_knots{pair}\",\n",
    "        f\"smoothness{pair}\",\n",
    "        f\"knot_uniformity{pair}\",\n",
    "        f\"expected_gradient_norm{pair}\",\n",
    "    ]\n",
    "\n",
    "\n",
    "for dataset, df in full_dfs.items():\n",
    "    print(\"dataset: \", dataset)\n",
    "    print(f\"len before dropna: {len(df)}\")\n",
    "\n",
    "    # print entries with na\n",
    "    # print(df[df[target_cols].isna().any(axis=1)])\n",
    "\n",
    "    # remove NA rows from the dataframe\n",
    "    df.dropna(subset=target_cols, inplace=True)\n",
    "\n",
    "    print(f\"len after dropna: {len(df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_dfs[\"downsampled_mnist\"][\"augment\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_dfs[\"downsampled_mnist\"][\"num_train\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_dfs[\"mnist\"][\"augment\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "big_data_full_augment_dfs = {}\n",
    "for big_data in [False, True]:\n",
    "    for full_augment in [False, True]:\n",
    "        dfs = {}\n",
    "        for dataset, df in full_dfs.items():\n",
    "            if dataset == \"mnist\":\n",
    "                num_train = 60000 if big_data else 10000\n",
    "                augment = \"rotflip\" if full_augment else \"trivial\"\n",
    "            elif dataset == \"cifar10\":\n",
    "                num_train = 50000 if big_data else 10000\n",
    "                augment = \"rot90flip\" if full_augment else \"trivial\"\n",
    "            elif dataset == \"moons\":\n",
    "                num_train = 10000 if big_data else 500\n",
    "                augment = \"flipH_and_or_flipW\" if full_augment else \"trivial\"\n",
    "            elif dataset == \"downsampled_mnist\":\n",
    "                num_train = 60000 if big_data else 10000\n",
    "                augment = \"translateH_and_or_W\" if full_augment else \"trivial\"\n",
    "            dfs[dataset] = df[\n",
    "                (df[\"augment\"] == augment) & (df[\"num_train\"] == num_train)\n",
    "            ].copy()\n",
    "        big_data_full_augment_dfs[(big_data, full_augment)] = dfs\n",
    "\n",
    "for dataset in full_dfs.keys():\n",
    "    # print dataset name, and number of elements in full and reduced\n",
    "    print(\"dataset:\\t\", dataset)\n",
    "    print(f\"full:   \\t {len(full_dfs[dataset])}\")\n",
    "    print(f\"reduced:  \\t {len(dfs[dataset])}\")\n",
    "    print()\n",
    "\n",
    "dfs = big_data_full_augment_dfs[(USE_BIG_DATA, USE_FULL_AUGMENT)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "# find unique groups, sort by group size\n",
    "unique_groups = {}\n",
    "unique_group_orders = {}\n",
    "unique_group_channels = {}\n",
    "unique_parameter_factors = {}\n",
    "\n",
    "for dataset, df in dfs.items():\n",
    "    unique_groups[dataset] = list(df[\"group\"].unique())\n",
    "    unique_group_channels[dataset] = list(df[\"hidden_group_channels\"].unique())\n",
    "    unique_parameter_factors[dataset] = list(df[\"parameter_factor\"].unique())\n",
    "    unique_group_orders[dataset] = list(df[\"group_order\"].unique())\n",
    "\n",
    "    unique_groups[dataset].sort(key=lambda x: group_sizes[x])\n",
    "    unique_group_channels[dataset].sort()\n",
    "    unique_parameter_factors[dataset].sort()\n",
    "    unique_group_orders[dataset].sort()\n",
    "\n",
    "    print(unique_groups[dataset])\n",
    "    print(unique_group_channels[dataset])\n",
    "    print(unique_parameter_factors[dataset])\n",
    "    print(unique_group_orders[dataset])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_proper_names = {\n",
    "    \"total_num_knots\": \"# Knots (K)\",\n",
    "    \"expected_knot_uniformity\": \"Knot Uniformity $(\\omega^2)$\",\n",
    "    \"expected_gradient_norm\": \"Sensitivity (Sn)\",\n",
    "    \"sqrt_total_smoothness\": \"Smoothness $(\\sqrt{ S }$)\",\n",
    "    \"val_accuracy\": \"Training Accuracy\",\n",
    "    \"val_loss\": \"Training Loss\",\n",
    "    \"test_accuracy\": \"Test Accuracy\",\n",
    "    \"test_loss\": \"Test Loss\",\n",
    "    \"total_smoothness\": \"Smoothness ($S$)\",\n",
    "    \"expected_knot_entropy\": \"Entropy $(\\\\mathbb{ H })$\",\n",
    "    \"generalization_gap\": \"Generalization Gap\",\n",
    "    \"generalization_ratio\": \"Standarized Generalization Gap\",\n",
    "    \"expected_gradient_norm_normalized_smoothness\": \"$\\\\frac{\\sqrt{ S }}{ \\mathrm{Sn} }$\",\n",
    "}\n",
    "\n",
    "plt_facecolors = [\"lightyellow\", \"honeydew\", \"lightcyan\", \"mistyrose\"]\n",
    "\n",
    "dataset_proper_names = {\n",
    "    \"mnist\": r\"MNIST $O(2)$\",\n",
    "    \"moons\": r\"Moons $K_4$\",\n",
    "    \"downsampled_mnist\": r\"Downsampled MNIST $\\mathbb{Z}^2_7$\",\n",
    "    \"cifar10\": r\"CIFAR10 $D_4$\",\n",
    "}\n",
    "\n",
    "cifar10_df = dfs.pop(\"cifar10\")\n",
    "# \\mathrm removes the italics from the text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Without CIFAR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig, ax = plt.subplots(len(selected_target_cols), 3, figsize=(14, 12))#, sharex=\"col\", sharey=\"row\")\n",
    "\n",
    "selected_target_cols = main_target_cols\n",
    "\n",
    "fig, ax = plt.subplots(\n",
    "    len(selected_target_cols), len(dfs.items()), figsize=(14, 13)\n",
    ")  # , sharex=\"col\", sharey=\"row\")\n",
    "for col, (dataset, df) in enumerate(dfs.items()):\n",
    "    for row, target_col in enumerate(selected_target_cols):\n",
    "        create_error_plots_custom(\n",
    "            df=df,\n",
    "            target_col=target_col,\n",
    "            covariate_col=\"hidden_group_channels\",\n",
    "            unique_covariates=unique_group_channels[dataset],\n",
    "            class_col=\"group\",\n",
    "            unique_classes=unique_groups[dataset],\n",
    "            aggregate_mode=\"mean\",\n",
    "            std_error=True,\n",
    "            ax=ax[row, col],\n",
    "            eps_noise_level=0.35,\n",
    "        )\n",
    "\n",
    "for a in ax.flatten():\n",
    "    # remove all titles from the plots\n",
    "    a.set_title(\"\")\n",
    "\n",
    "    # remove all x labels from the plots\n",
    "    a.set_xlabel(\"\")\n",
    "\n",
    "    # use larger font for titles, and set all yticks to right\n",
    "    a.yaxis.tick_right()\n",
    "\n",
    "    # larger font for yticks and xticks\n",
    "    a.yaxis.set_tick_params(labelsize=13)\n",
    "    a.xaxis.set_tick_params(labelsize=13)\n",
    "\n",
    "    # Force scientific notation\n",
    "    a.ticklabel_format(style=\"scientific\", axis=\"y\", scilimits=(0, 0), useMathText=True)\n",
    "    a.yaxis.set_major_locator(MaxNLocator(nbins=3, prune=\"upper\", min_n_ticks=3))\n",
    "    a.xaxis.set_major_locator(MaxNLocator(nbins=5, prune=\"both\"))\n",
    "\n",
    "# only keep y axis labels of left most plots\n",
    "for a in ax[:, 1:].flatten():\n",
    "    a.set_ylabel(\"\")\n",
    "\n",
    "# only keep x axis labels of bottom plots\n",
    "# for a in ax[-1:, :].flatten():\n",
    "# a.set_xlabel(\"hidden_group_channels\")\n",
    "\n",
    "# large size\n",
    "ax[-1, 1].set_xlabel(\"group-expanded channels\", fontsize=16, labelpad=10)\n",
    "\n",
    "# remove all xticks, except bottom row\n",
    "for a in ax[:-1, :].flatten():\n",
    "    a.set_xticks([])\n",
    "    a.set_xticklabels([])\n",
    "\n",
    "# remove legends\n",
    "for a in ax.flatten():\n",
    "    if a.get_legend() is not None:\n",
    "        a.get_legend().remove()\n",
    "\n",
    "# add legends to the top of the figure\n",
    "# top left\n",
    "ax[0, 0].legend(loc=\"upper left\", bbox_to_anchor=(0, 1), ncol=1, fontsize=11)\n",
    "# top middle\n",
    "ax[0, 1].legend(loc=\"upper left\", bbox_to_anchor=(0, 1), ncol=2, fontsize=11)\n",
    "# top right\n",
    "ax[0, 2].legend(loc=\"upper left\", bbox_to_anchor=(0, 1), ncol=1, fontsize=11)\n",
    "\n",
    "# add title to each column\n",
    "for n, (dataset, df) in enumerate(dfs.items()):\n",
    "    ax[0, n].set_title(dataset_proper_names[dataset], fontsize=18)\n",
    "\n",
    "# set leftmost ytick labels appropriately\n",
    "for a in ax.flatten():\n",
    "    # if y axis label in metric_proper_names, set it to the proper name\n",
    "    if a.get_ylabel() in metric_proper_names:\n",
    "        # a.set_ylabel(metric_proper_names[a.get_ylabel()], fontsize=16, rotation=75, labelpad=25)\n",
    "        a.set_ylabel(metric_proper_names[a.get_ylabel()], fontsize=16, rotation=90)\n",
    "\n",
    "ax[0, 0].set_facecolor(plt_facecolors[0])\n",
    "ax[0, 2].set_facecolor(plt_facecolors[0])\n",
    "ax[2, 1].set_facecolor(plt_facecolors[1])\n",
    "ax[2, 2].set_facecolor(plt_facecolors[1])\n",
    "ax[3, 2].set_facecolor(plt_facecolors[2])\n",
    "ax[4, 2].set_facecolor(plt_facecolors[3])\n",
    "\n",
    "for a in ax.flatten():\n",
    "    a.set_ylim(bottom=min(0, a.get_ylim()[0]))\n",
    "    # bot, top = a.get_ylim()\n",
    "    # mid = (top + bot) / 2\n",
    "    # a.set_yticks([0, float(f\"{mid:.1e}\"), float(f\"{top:.1e}\")])\n",
    "\n",
    "# stack figures on top of each other\n",
    "fig.tight_layout()\n",
    "\n",
    "# but keep ample space between row elements\n",
    "plt.subplots_adjust(hspace=0.15)\n",
    "\n",
    "# save as pdf\n",
    "plt.savefig(\"figures/error_plots_wide.ignore.pdf\", dpi=300, bbox_inches=\"tight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# important shot plot:\n",
    "# focus on mnist plot.\n",
    "fig, ax = plt.subplots(len(minimal_key_target_cols), 2, figsize=(8, 8))\n",
    "\n",
    "dataset = \"mnist\"\n",
    "df = dfs[dataset]\n",
    "\n",
    "for row, target_col in enumerate(minimal_key_target_cols):\n",
    "    create_error_plots_custom(\n",
    "        df=df,\n",
    "        target_col=target_col,\n",
    "        covariate_col=\"hidden_group_channels\",\n",
    "        unique_covariates=unique_group_channels[dataset],\n",
    "        class_col=\"group\",\n",
    "        unique_classes=unique_groups[dataset],\n",
    "        aggregate_mode=\"mean\",\n",
    "        std_error=True,\n",
    "        ax=ax[row, 0],\n",
    "    )\n",
    "\n",
    "    create_error_plots_custom(\n",
    "        df=df,\n",
    "        target_col=target_col,\n",
    "        covariate_col=\"parameter_factor\",\n",
    "        unique_covariates=unique_parameter_factors[dataset],\n",
    "        class_col=\"group\",\n",
    "        unique_classes=unique_groups[dataset],\n",
    "        aggregate_mode=\"mean\",\n",
    "        std_error=True,\n",
    "        ax=ax[row, 1],\n",
    "    )\n",
    "\n",
    "for a in ax.flatten():\n",
    "    # remove all titles from the plots\n",
    "    a.set_title(\"\")\n",
    "\n",
    "    # remove all x labels from the plots\n",
    "    a.set_xlabel(\"\")\n",
    "\n",
    "    # a.xaxis.get_label().set_fontsize(16)\n",
    "    # a.yaxis.get_label().set_fontsize(16)\n",
    "\n",
    "    # Force scientific notation\n",
    "    a.ticklabel_format(style=\"scientific\", axis=\"y\", scilimits=(0, 0), useMathText=True)\n",
    "    a.yaxis.set_major_locator(MaxNLocator(nbins=3, prune=\"upper\", min_n_ticks=3))\n",
    "    a.xaxis.set_major_locator(MaxNLocator(nbins=5, prune=\"both\"))\n",
    "\n",
    "    a.tick_params(axis=\"x\", labelsize=12)\n",
    "    a.tick_params(axis=\"y\", labelsize=12)\n",
    "\n",
    "# set leftmost ytick labels appropriately\n",
    "for a in ax.flatten():\n",
    "    # if y axis label in metric_proper_names, set it to the proper name\n",
    "    if a.get_ylabel() in metric_proper_names:\n",
    "        a.set_ylabel(metric_proper_names[a.get_ylabel()], fontsize=16)\n",
    "\n",
    "# only keep y axis labels of left most plots\n",
    "for a in ax[:, 1:].flatten():\n",
    "    a.set_ylabel(\"\")\n",
    "\n",
    "# only keep x axis labels of bottom plots\n",
    "ax[-1, 0].set_xlabel(\"group-expanded channels\", fontsize=16)\n",
    "ax[-1, 1].set_xlabel(\"$\\propto$ trainable parameters\", fontsize=16)\n",
    "\n",
    "# remove all xticks, except bottom row\n",
    "for a in ax[:-1, :].flatten():\n",
    "    a.set_xticks([])\n",
    "    a.set_xticklabels([])\n",
    "\n",
    "for a in ax[:, 1].flatten():\n",
    "    a.yaxis.tick_right()\n",
    "\n",
    "# remove yticks and yticklabels except for right most plots. Put yticks on the right side.\n",
    "for a in ax[:, :1].flatten():\n",
    "    a.set_yticks([])\n",
    "    a.set_yticklabels([])\n",
    "\n",
    "# remove legends\n",
    "for a in ax.flatten():\n",
    "    if a.get_legend() is not None:\n",
    "        a.get_legend().remove()\n",
    "\n",
    "# add legends to the top of the figure\n",
    "# top left\n",
    "# ax[0, 0].legend(loc=\"upper left\", bbox_to_anchor=(0, 1), ncol=2)\n",
    "# use small legend\n",
    "ax[0, 0].legend(loc=\"upper left\", bbox_to_anchor=(0, 1), ncol=2, fontsize=12)\n",
    "\n",
    "# add title to each column\n",
    "# for n, (dataset, df) in enumerate(dfs.items()):\n",
    "#     ax[0, n].set_title(dataset)\n",
    "\n",
    "# remove fig title\n",
    "fig.suptitle(\"\")\n",
    "\n",
    "# draw a striped vertical line at the point 20 for ax[2, 1]\n",
    "# ax[0, 1].axvline(20, color=\"black\", ls=\"--\", alpha=0.75)\n",
    "# ax[1, 1].axvline(20, color=\"black\", ls=\"--\", alpha=0.75)\n",
    "ax[2, 1].axvline(20, color=\"black\", ls=\"--\", alpha=0.75)\n",
    "\n",
    "# make a legend for ax[2, 1], only including the striped vertical line\n",
    "# ax[2, 1].legend([\"literature comparison\"], loc=\"upper right\", bbox_to_anchor=(0, 1), ncol=1)\n",
    "ax[2, 1].legend([\"literature comparison\"], loc=\"upper right\", fontsize=12)\n",
    "\n",
    "# stack figures on top of each other\n",
    "fig.tight_layout()\n",
    "\n",
    "# save as pdf\n",
    "plt.savefig(\n",
    "    \"figures/important_plot.ignore.pdf\", dpi=300, bbox_inches=\"tight\", pad_inches=0.1\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CIFAR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for appendix in [False, True]:\n",
    "    if appendix:\n",
    "        selected_target_cols = alternative_target_cols\n",
    "        fig, ax = plt.subplots(\n",
    "            len(selected_target_cols),\n",
    "            len(dfs.items()),\n",
    "            figsize=(14, 13 / len(main_target_cols) * len(selected_target_cols)),\n",
    "        )  # , sharex=\"col\", sharey=\"row\")\n",
    "    else:\n",
    "        selected_target_cols = main_target_cols\n",
    "        fig, ax = plt.subplots(\n",
    "            len(selected_target_cols), len(dfs.items()), figsize=(14, 13)\n",
    "        )  # , sharex=\"col\", sharey=\"row\")\n",
    "\n",
    "    # fig, ax = plt.subplots(len(selected_target_cols), 3, figsize=(14, 12))#, sharex=\"col\", sharey=\"row\")\n",
    "\n",
    "    dataset = \"cifar10\"\n",
    "    df = cifar10_df\n",
    "    group_order_pairings = [(1, 8), (2,), (4,)]\n",
    "\n",
    "    for col, pairing in enumerate(group_order_pairings):\n",
    "        for row, target_col in enumerate(selected_target_cols):\n",
    "            create_error_plots_custom(\n",
    "                df=df[df[\"group_order\"].isin(pairing)],\n",
    "                target_col=target_col,\n",
    "                covariate_col=\"hidden_group_channels\",\n",
    "                unique_covariates=unique_group_channels[dataset],\n",
    "                class_col=\"group\",\n",
    "                unique_classes=unique_groups[dataset],\n",
    "                aggregate_mode=\"mean\",\n",
    "                std_error=True,\n",
    "                ax=ax[row, col],\n",
    "                eps_noise_level=0.35,\n",
    "            )\n",
    "\n",
    "    for a in ax.flatten():\n",
    "        # remove all titles from the plots\n",
    "        a.set_title(\"\")\n",
    "\n",
    "        # remove all x labels from the plots\n",
    "        a.set_xlabel(\"\")\n",
    "\n",
    "        # use larger font for titles, and set all yticks to right\n",
    "        a.yaxis.tick_right()\n",
    "\n",
    "        # larger font for yticks and xticks\n",
    "        a.yaxis.set_tick_params(labelsize=13)\n",
    "        a.xaxis.set_tick_params(labelsize=13)\n",
    "\n",
    "        # Force scientific notation\n",
    "        a.ticklabel_format(\n",
    "            style=\"scientific\", axis=\"y\", scilimits=(0, 0), useMathText=True\n",
    "        )\n",
    "        a.yaxis.set_major_locator(MaxNLocator(nbins=5, prune=None, min_n_ticks=5))\n",
    "        a.xaxis.set_major_locator(MaxNLocator(nbins=7, prune=\"both\"))\n",
    "\n",
    "    # only keep y axis ticks of right most plots\n",
    "    for a in ax[:, :-1].flatten():\n",
    "        a.set_yticklabels([])\n",
    "\n",
    "    # only keep y axis labels of left most plots\n",
    "    for a in ax[:, 1:].flatten():\n",
    "        a.set_ylabel(\"\")\n",
    "\n",
    "    # only keep x axis labels of bottom plots\n",
    "    # for a in ax[-1:, :].flatten():\n",
    "    # a.set_xlabel(\"hidden_group_channels\")\n",
    "\n",
    "    # large size\n",
    "    ax[-1, 1].set_xlabel(\"group-expanded channels\", fontsize=16, labelpad=10)\n",
    "\n",
    "    # add x and y axis grid lines to all plots\n",
    "    for a in ax.flatten():\n",
    "        # Manually set grid lines\n",
    "        a.grid(True)\n",
    "\n",
    "    # remove all xticks, except bottom row\n",
    "    for a in ax[:-1, :].flatten():\n",
    "        a.set_xticklabels([])\n",
    "\n",
    "    # remove legends\n",
    "    for a in ax.flatten():\n",
    "        if a.get_legend() is not None:\n",
    "            a.get_legend().remove()\n",
    "\n",
    "    # add legends to the top of the figure\n",
    "    def _filter_ax_legend(ax, desired_labels, ncol=1):\n",
    "        # Get the current handles and labels\n",
    "        handles, labels = ax.get_legend_handles_labels()\n",
    "\n",
    "        # Filter the handles and labels\n",
    "        filtered_handles = [\n",
    "            handle for handle, label in zip(handles, labels) if label in desired_labels\n",
    "        ]\n",
    "        filtered_labels = [label for label in labels if label in desired_labels]\n",
    "\n",
    "        # modify property of filtered_labels's text to display metric proper names\n",
    "        filtered_labels = [group_info[label][1] for label in filtered_labels]\n",
    "\n",
    "        # Create a new legend with the filtered handles and labels\n",
    "        ax.legend(\n",
    "            filtered_handles,\n",
    "            filtered_labels,\n",
    "            # loc=\"upper left\" if not appendix else \"lower right\",\n",
    "            loc=\"lower right\" if not appendix else \"lower right\",\n",
    "            ncol=ncol,\n",
    "            fontsize=10,\n",
    "        )\n",
    "\n",
    "    # top left\n",
    "    ax[0, 0].legend(loc=\"lower left\", ncol=1, fontsize=11)\n",
    "    _filter_ax_legend(ax[0, 0], [\"trivial\", \"D4\"])\n",
    "    # top middle\n",
    "    ax[0, 1].legend(loc=\"lower left\", ncol=2, fontsize=11)\n",
    "    _filter_ax_legend(\n",
    "        ax[0, 1],\n",
    "        [\"flipW\", \"flipH\", \"rot180\", \"transpose\", \"antidiagonal_transpose\"],\n",
    "        ncol=2,\n",
    "    )\n",
    "    # top right\n",
    "    ax[0, 2].legend(loc=\"lower left\", ncol=1, fontsize=11)\n",
    "    _filter_ax_legend(\n",
    "        ax[0, 2],\n",
    "        [\"rot180_and_or_transpose\", \"rot90\", \"flipH_and_or_flipW\"],\n",
    "        ncol=1,\n",
    "    )\n",
    "\n",
    "    # add title to each column\n",
    "    for col in range(3):\n",
    "        ax[0, col].set_title(group_order_pairings[col], fontsize=18)\n",
    "\n",
    "    # set leftmost ytick labels appropriately\n",
    "    for a in ax.flatten():\n",
    "        # if y axis label in metric_proper_names, set it to the proper name\n",
    "        if a.get_ylabel() in metric_proper_names:\n",
    "            # a.set_ylabel(metric_proper_names[a.get_ylabel()], fontsize=16, rotation=75, labelpad=25)\n",
    "            a.set_ylabel(metric_proper_names[a.get_ylabel()], fontsize=16, rotation=90)\n",
    "\n",
    "    # ensure that every row has the same y limits\n",
    "    for row in range(len(selected_target_cols)):\n",
    "        y_lims = [a.get_ylim() for a in ax[row, :]]\n",
    "        y_lims = [min([lim[0] for lim in y_lims]), max([lim[1] for lim in y_lims])]\n",
    "        for a in ax[row, :]:\n",
    "            a.set_ylim(y_lims)\n",
    "\n",
    "    if appendix:\n",
    "        # Ensure y-axis scaling and ticks are shared for ax[2, :] and ax[3, :]\n",
    "        min_y = min(\n",
    "            ax[2, 0].get_ylim()[0],\n",
    "            ax[2, 1].get_ylim()[0],\n",
    "            ax[3, 0].get_ylim()[0],\n",
    "            ax[3, 1].get_ylim()[0],\n",
    "        )\n",
    "        max_y = max(\n",
    "            ax[2, 0].get_ylim()[1],\n",
    "            ax[2, 1].get_ylim()[1],\n",
    "            ax[3, 0].get_ylim()[1],\n",
    "            ax[3, 1].get_ylim()[1],\n",
    "        )\n",
    "        for a in ax[2, :]:\n",
    "            a.set_ylim(min_y, max_y)\n",
    "        for a in ax[3, :]:\n",
    "            a.set_ylim(min_y, max_y)\n",
    "\n",
    "    # set title of every column\n",
    "    ax[0, 0].set_title(\"{1, 8}\", fontsize=18)\n",
    "    ax[0, 1].set_title(\"{2}\", fontsize=18)\n",
    "    ax[0, 2].set_title(\"{4}\", fontsize=18)\n",
    "\n",
    "    # stack figures on top of each other\n",
    "    fig.tight_layout()\n",
    "\n",
    "    # but keep ample space between row elements\n",
    "    plt.subplots_adjust(hspace=0.15)\n",
    "\n",
    "    # save as pdf\n",
    "    plt.savefig(\n",
    "        f\"figures/cifar10_per_group_appendix={appendix}.ignore.pdf\",\n",
    "        dpi=300,\n",
    "        bbox_inches=\"tight\",\n",
    "    )\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_groups = [\n",
    "    (\"knots\", [\"total_num_knots\", \"expected_knot_uniformity\", \"expected_knot_entropy\"]),\n",
    "    (\n",
    "        \"smoothnesses\",\n",
    "        [\n",
    "            \"expected_gradient_norm\",\n",
    "            \"sqrt_total_smoothness\",\n",
    "            \"expected_gradient_norm_normalized_smoothness\",\n",
    "        ],\n",
    "    ),\n",
    "    (\"losses\", [\"val_loss\", \"test_loss\", \"generalization_gap\"]),\n",
    "]\n",
    "\n",
    "for plot_group_name, plot_group in plot_groups:\n",
    "    fig, ax = plt.subplots(\n",
    "        len(plot_group),\n",
    "        len(dfs.items()),\n",
    "        figsize=(14, 13 / len(main_target_cols) * len(plot_group)),\n",
    "    )\n",
    "\n",
    "    dataset = \"cifar10\"\n",
    "    df = cifar10_df\n",
    "    group_order_pairings = [(1, 8), (2,), (4,)]\n",
    "\n",
    "    for col, pairing in enumerate(group_order_pairings):\n",
    "        for row, target_col in enumerate(plot_group):\n",
    "            create_error_plots_custom(\n",
    "                df=df[df[\"group_order\"].isin(pairing)],\n",
    "                target_col=target_col,\n",
    "                covariate_col=\"hidden_group_channels\",\n",
    "                unique_covariates=unique_group_channels[dataset],\n",
    "                class_col=\"group\",\n",
    "                unique_classes=unique_groups[dataset],\n",
    "                aggregate_mode=\"mean\",\n",
    "                std_error=True,\n",
    "                ax=ax[row, col],\n",
    "                eps_noise_level=0.35,\n",
    "            )\n",
    "\n",
    "    for a in ax.flatten():\n",
    "        a.set_title(\"\")\n",
    "        a.set_xlabel(\"\")\n",
    "        a.yaxis.tick_right()\n",
    "        a.yaxis.set_tick_params(labelsize=13)\n",
    "        a.xaxis.set_tick_params(labelsize=13)\n",
    "        a.ticklabel_format(\n",
    "            style=\"scientific\", axis=\"y\", scilimits=(0, 0), useMathText=True\n",
    "        )\n",
    "        a.yaxis.set_major_locator(MaxNLocator(nbins=5, prune=None, min_n_ticks=5))\n",
    "        a.xaxis.set_major_locator(MaxNLocator(nbins=7, prune=\"both\"))\n",
    "\n",
    "    for a in ax[:, :-1].flatten():\n",
    "        a.set_yticklabels([])\n",
    "\n",
    "    for a in ax[:, 1:].flatten():\n",
    "        a.set_ylabel(\"\")\n",
    "\n",
    "    ax[-1, 1].set_xlabel(\"group-expanded channels\", fontsize=16, labelpad=10)\n",
    "\n",
    "    for a in ax.flatten():\n",
    "        a.grid(True)\n",
    "\n",
    "    for a in ax[:-1, :].flatten():\n",
    "        a.set_xticklabels([])\n",
    "\n",
    "    for a in ax.flatten():\n",
    "        if a.get_legend() is not None:\n",
    "            a.get_legend().remove()\n",
    "\n",
    "    def _filter_ax_legend(ax, desired_labels, ncol=1, loc=\"lower right\"):\n",
    "        handles, labels = ax.get_legend_handles_labels()\n",
    "        filtered_handles = [\n",
    "            handle for handle, label in zip(handles, labels) if label in desired_labels\n",
    "        ]\n",
    "        filtered_labels = [label for label in labels if label in desired_labels]\n",
    "        filtered_labels = [group_info[label][1] for label in filtered_labels]\n",
    "        ax.legend(\n",
    "            filtered_handles,\n",
    "            filtered_labels,\n",
    "            loc=loc,\n",
    "            ncol=ncol,\n",
    "            fontsize=10,\n",
    "        )\n",
    "\n",
    "    if plot_group_name == \"knots\":\n",
    "        loc = \"lower right\"\n",
    "    elif plot_group_name == \"smoothnesses\":\n",
    "        loc = \"upper left\"\n",
    "    elif plot_group_name == \"losses\":\n",
    "        loc = \"lower left\"\n",
    "    else:\n",
    "        raise ValueError(\"Unknown plot group\")\n",
    "\n",
    "    ax[0, 0].legend(loc=\"lower left\", ncol=1, fontsize=11)\n",
    "    _filter_ax_legend(ax[0, 0], [\"trivial\", \"D4\"], loc=loc)\n",
    "    ax[0, 1].legend(loc=\"lower left\", ncol=2, fontsize=11)\n",
    "    _filter_ax_legend(\n",
    "        ax[0, 1],\n",
    "        [\"flipW\", \"flipH\", \"rot180\", \"transpose\", \"antidiagonal_transpose\"],\n",
    "        ncol=2,\n",
    "        loc=loc,\n",
    "    )\n",
    "    ax[0, 2].legend(loc=\"lower left\", ncol=1, fontsize=11)\n",
    "    _filter_ax_legend(\n",
    "        ax[0, 2],\n",
    "        [\"rot180_and_or_transpose\", \"rot90\", \"flipH_and_or_flipW\"],\n",
    "        ncol=1,\n",
    "        loc=loc,\n",
    "    )\n",
    "\n",
    "    for col in range(3):\n",
    "        ax[0, col].set_title(\n",
    "            f\"{{{', '.join(map(str, group_order_pairings[col]))}}}\", fontsize=18\n",
    "        )\n",
    "\n",
    "    for a in ax.flatten():\n",
    "        if a.get_ylabel() in metric_proper_names:\n",
    "            a.set_ylabel(metric_proper_names[a.get_ylabel()], fontsize=16, rotation=90)\n",
    "\n",
    "    for row in range(len(plot_group)):\n",
    "        y_lims = [a.get_ylim() for a in ax[row, :]]\n",
    "        y_lims = [min([lim[0] for lim in y_lims]), max([lim[1] for lim in y_lims])]\n",
    "        for a in ax[row, :]:\n",
    "            a.set_ylim(y_lims)\n",
    "\n",
    "    fig.tight_layout()\n",
    "    plt.subplots_adjust(hspace=0.15)\n",
    "    plt.savefig(\n",
    "        f\"figures/cifar10_per_group_{plot_group_name}.ignore.pdf\",\n",
    "        dpi=300,\n",
    "        bbox_inches=\"tight\",\n",
    "    )\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# selected_target_cols = [\"total_smoothness\", \"val_loss\", \"expected_knot_uniformity\"]\n",
    "# selected_target_cols = main_target_cols\n",
    "selected_target_cols = [\n",
    "    \"total_num_knots\",\n",
    "    \"expected_gradient_norm\",\n",
    "    \"val_loss\",\n",
    "    \"test_loss\",\n",
    "]\n",
    "# selected_target_cols = [\"total_num_knots\", \"expected_gradient_norm\", \"val_loss\", \"expected_knot_uniformity\"]\n",
    "fig, ax = plt.subplots(\n",
    "    # 1, len(selected_target_cols), figsize=(14, 13 / len(main_target_cols) * len(selected_target_cols))\n",
    "    2,\n",
    "    2,\n",
    "    figsize=(9, 7),\n",
    ")  # , sharex=\"col\", sharey=\"row\")\n",
    "\n",
    "dataset = \"cifar10\"\n",
    "df = cifar10_df\n",
    "# group_order_pairings = [(1, 8), (2,), (4,)]\n",
    "unique_groups_order_2 = df[df[\"group_order\"] == 2][\"group\"].unique()\n",
    "\n",
    "# only use hidden_group_channels > 30 and less than 40\n",
    "df = df[(df[\"hidden_group_channels\"] > 22) & (df[\"hidden_group_channels\"] < 60)]\n",
    "\n",
    "loc = [(0, 0), (0, 1), (1, 0), (1, 1)]\n",
    "\n",
    "for (row, col), target_col in zip(loc, selected_target_cols):\n",
    "    create_error_plots_custom(\n",
    "        df=df[df[\"group_order\"] == 2],\n",
    "        target_col=target_col,\n",
    "        covariate_col=\"hidden_group_channels\",\n",
    "        unique_covariates=unique_group_channels[dataset],\n",
    "        class_col=\"group\",\n",
    "        unique_classes=unique_groups_order_2,\n",
    "        aggregate_mode=\"mean\",\n",
    "        std_error=True,\n",
    "        ax=ax[row, col],\n",
    "        eps_noise_level=0.45,\n",
    "    )\n",
    "    # ax[row].set_title(metric_proper_names[selected_target_cols[row]], fontsize=18)\n",
    "    ax[row, col].set_ylabel(metric_proper_names[target_col], fontsize=18)\n",
    "\n",
    "for a in ax.flatten():\n",
    "    # remove all x labels from the plots\n",
    "    a.set_xlabel(\"\")\n",
    "\n",
    "    # use larger font for titles, and set all yticks to right\n",
    "    a.yaxis.tick_right()\n",
    "\n",
    "    # larger font for yticks and xticks\n",
    "    a.yaxis.set_tick_params(labelsize=13)\n",
    "    a.xaxis.set_tick_params(labelsize=13)\n",
    "\n",
    "    # Force scientific notation\n",
    "    a.ticklabel_format(style=\"scientific\", axis=\"y\", scilimits=(0, 0), useMathText=True)\n",
    "    a.yaxis.set_major_locator(MaxNLocator(nbins=5, prune=None, min_n_ticks=5))\n",
    "    a.xaxis.set_major_locator(MaxNLocator(nbins=7, prune=\"both\"))\n",
    "\n",
    "    # remove title\n",
    "    a.set_title(\"\")\n",
    "\n",
    "# # only keep y axis ticks of right most plots\n",
    "# for a in ax[:, :-1].flatten():\n",
    "#     a.set_yticklabels([])\n",
    "\n",
    "# # only keep y axis labels of left most plots\n",
    "# for a in ax.flatten():\n",
    "#     a.set_ylabel(\"\")\n",
    "\n",
    "# only keep x axis labels of bottom plots\n",
    "for a in ax[-1:, :].flatten():\n",
    "    a.set_xlabel(\"hidden_group_channels\")\n",
    "\n",
    "# remove x ticks of top plots\n",
    "for a in ax[:-1, :].flatten():\n",
    "    a.set_xticks([])\n",
    "    a.set_xticklabels([])\n",
    "\n",
    "# # large size\n",
    "# ax[-1, 1].set_xlabel(\"group-expanded channels\", fontsize=16, labelpad=10)\n",
    "\n",
    "# # add x and y axis grid lines to all plots\n",
    "# for a in ax.flatten():\n",
    "#     # Manually set grid lines\n",
    "#     a.grid(True)\n",
    "\n",
    "# # remove all xticks, except bottom row\n",
    "# for a in ax[:-1, :].flatten():\n",
    "#     a.set_xticklabels([])\n",
    "\n",
    "# remove legends\n",
    "for a in ax.flatten():\n",
    "    if a.get_legend() is not None:\n",
    "        a.get_legend().remove()\n",
    "\n",
    "\n",
    "# # top left\n",
    "ax[0, 0].legend(loc=\"upper left\", ncol=1, fontsize=11)\n",
    "\n",
    "# use proper names for legend in ax[0, 0]\n",
    "# use all groups of order 2\n",
    "_filter_ax_legend(ax[0, 0], unique_groups_order_2, ncol=1)\n",
    "\n",
    "# change xlabel to group-expanded channels\n",
    "ax[1, 0].set_xlabel(\"group-expanded channels\", fontsize=16)\n",
    "ax[1, 1].set_xlabel(\"group-expanded channels\", fontsize=16)\n",
    "\n",
    "# # add title to each column\n",
    "# for col in range(len(selected_target_cols)):\n",
    "#     ax[col].set_title(selected_target_cols[3], fontsize=18)\n",
    "\n",
    "# # ensure that every row has the same y limits\n",
    "# for row in range(len(selected_target_cols)):\n",
    "#     y_lims = [a.get_ylim() for a in ax[row, :]]\n",
    "#     y_lims = [min([lim[0] for lim in y_lims]), max([lim[1] for lim in y_lims])]\n",
    "#     for a in ax[row, :]:\n",
    "#         a.set_ylim(y_lims)\n",
    "\n",
    "# if appendix:\n",
    "#     # Ensure y-axis scaling and ticks are shared for ax[2, :] and ax[3, :]\n",
    "#     min_y = min(ax[2, 0].get_ylim()[0], ax[2, 1].get_ylim()[0], ax[3, 0].get_ylim()[0], ax[3, 1].get_ylim()[0])\n",
    "#     max_y = max(ax[2, 0].get_ylim()[1], ax[2, 1].get_ylim()[1], ax[3, 0].get_ylim()[1], ax[3, 1].get_ylim()[1])\n",
    "#     for a in ax[2, :]:\n",
    "#         a.set_ylim(min_y, max_y)\n",
    "#     for a in ax[3, :]:\n",
    "#         a.set_ylim(min_y, max_y)\n",
    "\n",
    "# stack figures on top of each other\n",
    "fig.tight_layout()\n",
    "\n",
    "# but keep ample space between row elements\n",
    "plt.subplots_adjust(hspace=0.1)\n",
    "\n",
    "# save as pdf\n",
    "plt.savefig(\n",
    "    f\"figures/cifar10_only_group_order_2.ignore.pdf\", dpi=300, bbox_inches=\"tight\"\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# important shot plot:\n",
    "for appendix in [False, True]:\n",
    "    if appendix:\n",
    "        selected_target_cols = alternative_target_cols\n",
    "        fig, ax = plt.subplots(\n",
    "            len(selected_target_cols), 2, figsize=(7, 7 * len(selected_target_cols) / 3)\n",
    "        )\n",
    "    else:\n",
    "        selected_target_cols = main_target_cols\n",
    "        fig, ax = plt.subplots(\n",
    "            len(selected_target_cols),\n",
    "            2,\n",
    "            figsize=(7, 7 * len(selected_target_cols) / len(minimal_key_target_cols)),\n",
    "        )\n",
    "\n",
    "    dataset = \"cifar10\"\n",
    "    df = cifar10_df[~cifar10_df[\"group\"].isin([\"transpose\", \"flipW\"])]\n",
    "    for row, target_col in enumerate(selected_target_cols):\n",
    "        create_error_plots_custom(\n",
    "            df,\n",
    "            target_col=target_col,\n",
    "            covariate_col=\"hidden_group_channels\",\n",
    "            unique_covariates=unique_group_channels[dataset],\n",
    "            class_col=\"group_order\",\n",
    "            unique_classes=unique_group_orders[dataset],\n",
    "            aggregate_mode=\"mean\",\n",
    "            std_error=True,\n",
    "            ax=ax[row, 0],\n",
    "        )\n",
    "\n",
    "        create_error_plots_custom(\n",
    "            df,\n",
    "            target_col=target_col,\n",
    "            covariate_col=\"parameter_factor\",\n",
    "            unique_covariates=unique_parameter_factors[dataset],\n",
    "            class_col=\"group_order\",\n",
    "            unique_classes=unique_group_orders[dataset],\n",
    "            aggregate_mode=\"mean\",\n",
    "            std_error=True,\n",
    "            ax=ax[row, 1],\n",
    "        )\n",
    "\n",
    "    for a in ax.flatten():\n",
    "        # remove all titles from the plots\n",
    "        a.set_title(\"\")\n",
    "\n",
    "        # remove all x labels from the plots\n",
    "        a.set_xlabel(\"\")\n",
    "        # larger font for yticks and xticks\n",
    "        a.yaxis.set_tick_params(labelsize=13)\n",
    "        a.xaxis.set_tick_params(labelsize=13)\n",
    "\n",
    "        # Force scientific notation\n",
    "        a.ticklabel_format(\n",
    "            style=\"scientific\", axis=\"y\", scilimits=(0, 0), useMathText=True\n",
    "        )\n",
    "        a.yaxis.set_major_locator(MaxNLocator(nbins=5, prune=None, min_n_ticks=5))\n",
    "        a.xaxis.set_major_locator(MaxNLocator(nbins=7, prune=\"both\"))\n",
    "        a.ticklabel_format(\n",
    "            style=\"scientific\", axis=\"y\", scilimits=(0, 0), useMathText=True\n",
    "        )\n",
    "        a.yaxis.set_major_locator(MaxNLocator(nbins=3, prune=\"upper\", min_n_ticks=3))\n",
    "        a.xaxis.set_major_locator(MaxNLocator(nbins=5, prune=\"both\"))\n",
    "\n",
    "        a.tick_params(axis=\"x\", labelsize=12)\n",
    "        a.tick_params(axis=\"y\", labelsize=12)\n",
    "\n",
    "    # set leftmost ytick labels appropriately\n",
    "    for a in ax.flatten():\n",
    "        # if y axis label in metric_proper_names, set it to the proper name\n",
    "        if a.get_ylabel() in metric_proper_names:\n",
    "            a.set_ylabel(metric_proper_names[a.get_ylabel()], fontsize=16)\n",
    "\n",
    "    # only keep y axis labels of left most plots\n",
    "    for a in ax[:, 1:].flatten():\n",
    "        a.set_ylabel(\"\")\n",
    "\n",
    "    # only keep x axis labels of bottom plots\n",
    "    ax[-1, 0].set_xlabel(\"group-expanded channels\", fontsize=16)\n",
    "    ax[-1, 1].set_xlabel(\"$\\propto$ trainable parameters\", fontsize=16)\n",
    "\n",
    "    # remove all xticks, except bottom row\n",
    "    for a in ax[:-1, :].flatten():\n",
    "        a.set_xticks([])\n",
    "        a.set_xticklabels([])\n",
    "\n",
    "    for a in ax[:, 1].flatten():\n",
    "        a.yaxis.tick_right()\n",
    "\n",
    "    # remove yticks and yticklabels except for right most plots. Put yticks on the right side.\n",
    "    for a in ax[:, :1].flatten():\n",
    "        a.set_yticks([])\n",
    "        a.set_yticklabels([])\n",
    "\n",
    "    # remove legends\n",
    "    for a in ax.flatten():\n",
    "        if a.get_legend() is not None:\n",
    "            a.get_legend().remove()\n",
    "\n",
    "    # add legends to the top of the figure\n",
    "    # top left\n",
    "    # ax[0, 0].legend(loc=\"upper left\", bbox_to_anchor=(0, 1), ncol=2)\n",
    "    # use small legend\n",
    "    ax[0, 0].legend(loc=\"upper left\", bbox_to_anchor=(0, 1), ncol=2, fontsize=12)\n",
    "\n",
    "    # add title to each column\n",
    "    # for n, (dataset, df) in enumerate(dfs.items()):\n",
    "    #     ax[0, n].set_title(dataset)\n",
    "\n",
    "    # remove fig title\n",
    "    fig.suptitle(\"\")\n",
    "\n",
    "    if not appendix:\n",
    "        # draw a striped vertical line at the point 20 for ax[2, 1]\n",
    "        ax[-1, 1].axvline(20, color=\"black\", ls=\"--\", alpha=0.75)\n",
    "\n",
    "        # make a legend for ax[2, 1], only including the striped vertical line\n",
    "        ax[-1, 1].legend([\"literature comparison\"], loc=\"upper right\", fontsize=12)\n",
    "\n",
    "    if appendix:\n",
    "        # Ensure y-axis scaling and ticks are shared for ax[2, :] and ax[3, :]\n",
    "        min_y = min(\n",
    "            ax[2, 0].get_ylim()[0],\n",
    "            ax[2, 1].get_ylim()[0],\n",
    "            ax[3, 0].get_ylim()[0],\n",
    "            ax[3, 1].get_ylim()[0],\n",
    "        )\n",
    "        max_y = max(\n",
    "            ax[2, 0].get_ylim()[1],\n",
    "            ax[2, 1].get_ylim()[1],\n",
    "            ax[3, 0].get_ylim()[1],\n",
    "            ax[3, 1].get_ylim()[1],\n",
    "        )\n",
    "        for a in ax[2, :]:\n",
    "            a.set_ylim(min_y, max_y)\n",
    "        for a in ax[3, :]:\n",
    "            a.set_ylim(min_y, max_y)\n",
    "\n",
    "    # stack figures on top of each other\n",
    "    fig.tight_layout()\n",
    "\n",
    "    # save as pdf\n",
    "    plt.savefig(\n",
    "        f\"figures/important_plot_cifar10_appendix={appendix}_extensive.ignore.pdf\",\n",
    "        dpi=300,\n",
    "        bbox_inches=\"tight\",\n",
    "        pad_inches=0.1,\n",
    "    )\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# important shot plot:\n",
    "# focus on mnist plot.\n",
    "fig, ax = plt.subplots(len(minimal_key_target_cols), 2, figsize=(8, 8))\n",
    "\n",
    "dataset = \"cifar10\"\n",
    "df = cifar10_df[~cifar10_df[\"group\"].isin([\"transpose\", \"flipW\"])]\n",
    "\n",
    "for row, target_col in enumerate(minimal_key_target_cols):\n",
    "    create_error_plots_custom(\n",
    "        df,\n",
    "        target_col=target_col,\n",
    "        covariate_col=\"hidden_group_channels\",\n",
    "        unique_covariates=unique_group_channels[dataset],\n",
    "        class_col=\"group_order\",\n",
    "        unique_classes=unique_group_orders[dataset],\n",
    "        aggregate_mode=\"mean\",\n",
    "        std_error=True,\n",
    "        ax=ax[row, 0],\n",
    "    )\n",
    "\n",
    "    create_error_plots_custom(\n",
    "        df,\n",
    "        target_col=target_col,\n",
    "        covariate_col=\"parameter_factor\",\n",
    "        unique_covariates=unique_parameter_factors[dataset],\n",
    "        class_col=\"group_order\",\n",
    "        unique_classes=unique_group_orders[dataset],\n",
    "        aggregate_mode=\"mean\",\n",
    "        std_error=True,\n",
    "        ax=ax[row, 1],\n",
    "    )\n",
    "\n",
    "for a in ax.flatten():\n",
    "    # remove all titles from the plots\n",
    "    a.set_title(\"\")\n",
    "\n",
    "    # remove all x labels from the plots\n",
    "    a.set_xlabel(\"\")\n",
    "\n",
    "    # a.xaxis.get_label().set_fontsize(16)\n",
    "    # a.yaxis.get_label().set_fontsize(16)\n",
    "\n",
    "    # Force scientific notation\n",
    "    a.ticklabel_format(style=\"scientific\", axis=\"y\", scilimits=(0, 0), useMathText=True)\n",
    "    a.yaxis.set_major_locator(MaxNLocator(nbins=3, prune=\"upper\", min_n_ticks=3))\n",
    "    a.xaxis.set_major_locator(MaxNLocator(nbins=5, prune=\"both\"))\n",
    "\n",
    "    a.tick_params(axis=\"x\", labelsize=12)\n",
    "    a.tick_params(axis=\"y\", labelsize=12)\n",
    "\n",
    "# set leftmost ytick labels appropriately\n",
    "for a in ax.flatten():\n",
    "    # if y axis label in metric_proper_names, set it to the proper name\n",
    "    if a.get_ylabel() in metric_proper_names:\n",
    "        a.set_ylabel(metric_proper_names[a.get_ylabel()], fontsize=16)\n",
    "\n",
    "# only keep y axis labels of left most plots\n",
    "for a in ax[:, 1:].flatten():\n",
    "    a.set_ylabel(\"\")\n",
    "\n",
    "# only keep x axis labels of bottom plots\n",
    "ax[-1, 0].set_xlabel(\"group-expanded channels\", fontsize=16)\n",
    "ax[-1, 1].set_xlabel(\"$\\propto$ trainable parameters\", fontsize=16)\n",
    "\n",
    "# remove all xticks, except bottom row\n",
    "for a in ax[:-1, :].flatten():\n",
    "    a.set_xticks([])\n",
    "    a.set_xticklabels([])\n",
    "\n",
    "for a in ax[:, 1].flatten():\n",
    "    a.yaxis.tick_right()\n",
    "\n",
    "# remove yticks and yticklabels except for right most plots. Put yticks on the right side.\n",
    "for a in ax[:, :1].flatten():\n",
    "    a.set_yticks([])\n",
    "    a.set_yticklabels([])\n",
    "\n",
    "# remove legends\n",
    "for a in ax.flatten():\n",
    "    if a.get_legend() is not None:\n",
    "        a.get_legend().remove()\n",
    "\n",
    "# add legends to the top of the figure\n",
    "# top left\n",
    "# ax[0, 0].legend(loc=\"upper left\", bbox_to_anchor=(0, 1), ncol=2)\n",
    "# use small legend\n",
    "ax[0, 0].legend(loc=\"upper left\", bbox_to_anchor=(0, 1), ncol=2, fontsize=12)\n",
    "\n",
    "# add title to each column\n",
    "# for n, (dataset, df) in enumerate(dfs.items()):\n",
    "#     ax[0, n].set_title(dataset)\n",
    "\n",
    "# remove fig title\n",
    "fig.suptitle(\"\")\n",
    "\n",
    "# draw a striped vertical line at the point 20 for ax[2, 1]\n",
    "# ax[0, 1].axvline(20, color=\"black\", ls=\"--\", alpha=0.75)\n",
    "# ax[1, 1].axvline(20, color=\"black\", ls=\"--\", alpha=0.75)\n",
    "ax[2, 1].axvline(20, color=\"black\", ls=\"--\", alpha=0.75)\n",
    "\n",
    "# make a legend for ax[2, 1], only including the striped vertical line\n",
    "# ax[2, 1].legend([\"literature comparison\"], loc=\"upper right\", bbox_to_anchor=(0, 1), ncol=1)\n",
    "ax[2, 1].legend([\"literature comparison\"], loc=\"upper right\", fontsize=12)\n",
    "\n",
    "# stack figures on top of each other\n",
    "fig.tight_layout()\n",
    "\n",
    "# save as pdf\n",
    "plt.savefig(\n",
    "    \"figures/important_plot_cifar10.ignore.pdf\",\n",
    "    dpi=300,\n",
    "    bbox_inches=\"tight\",\n",
    "    pad_inches=0.1,\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new set of plots on a 3x3 axes\n",
    "fig, ax = plt.subplots(3, 3, figsize=(12, 10))\n",
    "\n",
    "# Define the metrics to plot\n",
    "metrics = [\n",
    "    \"total_num_knots\",\n",
    "    \"expected_knot_uniformity\",\n",
    "    \"expected_knot_entropy\",\n",
    "    \"expected_gradient_norm\",\n",
    "    \"sqrt_total_smoothness\",\n",
    "    \"expected_gradient_norm_normalized_smoothness\",\n",
    "    \"val_loss\",\n",
    "    \"test_loss\",\n",
    "    \"generalization_gap\",\n",
    "]\n",
    "\n",
    "# use df that is cifar but not flipW or transpose\n",
    "dataset = \"cifar10\"\n",
    "df = cifar10_df[~cifar10_df[\"group\"].isin([\"transpose\", \"flipW\"])]\n",
    "\n",
    "# Plot each metric\n",
    "for i, metric in enumerate(metrics):\n",
    "    row, col = divmod(i, 3)\n",
    "    create_error_plots_custom(\n",
    "        df,\n",
    "        target_col=metric,\n",
    "        covariate_col=\"hidden_group_channels\",\n",
    "        unique_covariates=unique_group_channels[dataset],\n",
    "        class_col=\"group_order\",\n",
    "        unique_classes=unique_group_orders[dataset],\n",
    "        aggregate_mode=\"mean\",\n",
    "        std_error=True,\n",
    "        ax=ax[row, col],\n",
    "    )\n",
    "    ax[row, col].set_title(metric_proper_names[metric], fontsize=16)\n",
    "\n",
    "for a in ax.flatten():\n",
    "    # remove all titles from the plots\n",
    "    a.set_xlabel(\"\")\n",
    "    # larger font for yticks and xticks\n",
    "    a.yaxis.set_tick_params(labelsize=13)\n",
    "    a.xaxis.set_tick_params(labelsize=13)\n",
    "    a.yaxis.tick_right()\n",
    "\n",
    "    # Force scientific notation\n",
    "    a.ticklabel_format(style=\"scientific\", axis=\"y\", scilimits=(0, 0), useMathText=True)\n",
    "    a.yaxis.set_major_locator(MaxNLocator(nbins=5, prune=None, min_n_ticks=5))\n",
    "    a.xaxis.set_major_locator(MaxNLocator(nbins=7, prune=\"both\"))\n",
    "    a.ticklabel_format(style=\"scientific\", axis=\"y\", scilimits=(0, 0), useMathText=True)\n",
    "    a.yaxis.set_major_locator(MaxNLocator(nbins=3, prune=\"upper\", min_n_ticks=3))\n",
    "    a.xaxis.set_major_locator(MaxNLocator(nbins=5, prune=\"both\"))\n",
    "\n",
    "    a.tick_params(axis=\"x\", labelsize=12)\n",
    "    a.tick_params(axis=\"y\", labelsize=12)\n",
    "\n",
    "# Remove x-axes for all but the lowest plots\n",
    "for a in ax[:-1, :].flatten():\n",
    "    a.set_xticks([])\n",
    "    a.set_xticklabels([])\n",
    "    a.set_xlabel(\"\")\n",
    "\n",
    "# remove all other legends\n",
    "for a in ax.flatten():\n",
    "    if a.get_legend() is not None:\n",
    "        a.get_legend().remove()\n",
    "\n",
    "    # remove ylabel\n",
    "    a.set_ylabel(\"\")\n",
    "\n",
    "# only keep legend for the top left plot\n",
    "ax[0, 0].legend(loc=\"upper left\", bbox_to_anchor=(0, 1), ncol=1, fontsize=13)\n",
    "\n",
    "# Set x-axis label for the lowest plots\n",
    "ax[-1, 1].set_xlabel(\"group-expanded channels\", fontsize=16, labelpad=15)\n",
    "\n",
    "# Ensure y-axis scaling and ticks are shared for ax[2, 0] and ax[2, 1]\n",
    "min_y = min(ax[2, 0].get_ylim()[0], ax[2, 1].get_ylim()[0])\n",
    "max_y = max(ax[2, 0].get_ylim()[1], ax[2, 1].get_ylim()[1])\n",
    "ax[2, 0].set_ylim(min_y, max_y)\n",
    "ax[2, 1].set_ylim(min_y, max_y)\n",
    "\n",
    "# Adjust layout\n",
    "fig.tight_layout()\n",
    "\n",
    "# Save the figure\n",
    "plt.savefig(\n",
    "    f\"figures/cifar10_all_metrics_important.pdf\",\n",
    "    dpi=300,\n",
    "    bbox_inches=\"tight\",\n",
    "    pad_inches=0.1,\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raise Exception(\"stop notebook autorun\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
